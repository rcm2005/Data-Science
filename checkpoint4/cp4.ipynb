{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 3933.272649405236\n",
      "RMSE: 5641.626558850189\n",
      "R^2: 0.7999876970680435\n",
      "R^2 ajustado: 0.7930105237099521\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Carregando o dataset\n",
    "arquivo_csv = \"insurance.csv\"\n",
    "data_frame = pd.read_csv(arquivo_csv)\n",
    "\n",
    "# Processamento das variáveis categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Transformando as variáveis categóricas\n",
    "for coluna in data_frame.select_dtypes(include='object').columns:\n",
    "    if coluna != 'region':\n",
    "        data_frame[coluna] = label_encoder.fit_transform(data_frame[coluna])\n",
    "    else:\n",
    "        one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "        colunas_codificadas = one_hot_encoder.fit_transform(data_frame.loc[:, coluna:coluna])\n",
    "        df_colunas_transformadas = pd.DataFrame(colunas_codificadas, columns=one_hot_encoder.get_feature_names_out([coluna]))\n",
    "        df_codificado = pd.concat([data_frame, df_colunas_transformadas], axis=1)\n",
    "        df_codificado.drop([coluna], axis=1, inplace=True)\n",
    "        data_frame = df_codificado\n",
    "\n",
    "# Definindo as variáveis preditoras (excluindo 'charges')\n",
    "var_preditoras = data_frame.drop(['charges'], axis=1)\n",
    "var_alvo = data_frame['charges']\n",
    "\n",
    "# Separando os dados em treino e teste (80% treino, 20% teste)\n",
    "x_train, x_test, y_train, y_test = train_test_split(var_preditoras, var_alvo, test_size=0.2, random_state=0)\n",
    "\n",
    "# Treinamento do modelo de regressão linear\n",
    "modelo_reg_multi = LinearRegression()\n",
    "modelo_reg_multi.fit(x_train, y_train)\n",
    "\n",
    "# Previsões\n",
    "y_predicao = modelo_reg_multi.predict(x_test)\n",
    "\n",
    "# Avaliação do modelo: MAE, RMSE, R^2, R^2 ajustado\n",
    "mae = metrics.mean_absolute_error(y_test, y_predicao)\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test, y_predicao))\n",
    "r_sq = metrics.r2_score(y_test, y_predicao)\n",
    "n = len(y_test)\n",
    "k = x_test.shape[1]\n",
    "adjusted_r_squared = 1 - (1 - r_sq) * (n - 1) / (n - k - 1)\n",
    "\n",
    "# Exibindo os resultados\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R^2: {r_sq}\")\n",
    "print(f\"R^2 ajustado: {adjusted_r_squared}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                charges   R-squared:                       0.751\n",
      "Model:                            OLS   Adj. R-squared:                  0.749\n",
      "Method:                 Least Squares   F-statistic:                     500.8\n",
      "Date:                Sun, 29 Sep 2024   Prob (F-statistic):               0.00\n",
      "Time:                        21:24:55   Log-Likelihood:                -13548.\n",
      "No. Observations:                1338   AIC:                         2.711e+04\n",
      "Df Residuals:                    1329   BIC:                         2.716e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "const            -1.002e+04    781.640    -12.820      0.000   -1.16e+04   -8487.055\n",
      "age                256.8564     11.899     21.587      0.000     233.514     280.199\n",
      "sex               -131.3144    332.945     -0.394      0.693    -784.470     521.842\n",
      "bmi                339.1935     28.599     11.860      0.000     283.088     395.298\n",
      "children           475.5005    137.804      3.451      0.001     205.163     745.838\n",
      "smoker            2.385e+04    413.153     57.723      0.000     2.3e+04    2.47e+04\n",
      "region_northeast -1918.1003    333.386     -5.753      0.000   -2572.121   -1264.080\n",
      "region_northwest -2271.0642    333.477     -6.810      0.000   -2925.263   -1616.865\n",
      "region_southeast -2953.1224    384.752     -7.675      0.000   -3707.910   -2198.335\n",
      "region_southwest -2878.1513    350.871     -8.203      0.000   -3566.473   -2189.830\n",
      "==============================================================================\n",
      "Omnibus:                      300.366   Durbin-Watson:                   2.088\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              718.887\n",
      "Skew:                           1.211   Prob(JB):                    7.86e-157\n",
      "Kurtosis:                       5.651   Cond. No.                     3.40e+17\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 3.04e-29. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "MAE após remoção: 3933.272649405235\n",
      "RMSE após remoção: 5641.62655885019\n",
      "R^2 após remoção: 0.7999876970680433\n",
      "R^2 ajustado após remoção: 0.7922051171874224\n"
     ]
    }
   ],
   "source": [
    "# Cálculo dos p-valores para todas as variáveis preditoras\n",
    "var_preditoras2 = sm.add_constant(data_frame.drop(['charges'], axis=1))\n",
    "estimacao = sm.OLS(data_frame['charges'], var_preditoras2)\n",
    "estimacao_pvalor = estimacao.fit()\n",
    "\n",
    "# Mostra o sumário com p-valores\n",
    "print(estimacao_pvalor.summary())\n",
    "\n",
    "# Com base nos p-valores, escolhemos a variável com maior p-valor para remover.\n",
    "# Suponhamos que a variável 'region_southwest' tenha o maior p-valor.\n",
    "\n",
    "# Removendo a variável com o maior p-valor\n",
    "var_preditoras_sem_region_southwest = var_preditoras.drop(['region_southwest'], axis=1)\n",
    "\n",
    "# Separando novamente os dados em treino e teste\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(var_preditoras_sem_region_southwest, var_alvo, test_size=0.2, random_state=0)\n",
    "\n",
    "# Re-treinando o modelo\n",
    "modelo_reg_multi2 = LinearRegression()\n",
    "modelo_reg_multi2.fit(x_train2, y_train2)\n",
    "\n",
    "# Fazendo as previsões\n",
    "y_predicao2 = modelo_reg_multi2.predict(x_test2)\n",
    "\n",
    "# Avaliando o novo modelo\n",
    "mae2 = metrics.mean_absolute_error(y_test2, y_predicao2)\n",
    "rmse2 = np.sqrt(metrics.mean_squared_error(y_test2, y_predicao2))\n",
    "r_sq2 = metrics.r2_score(y_test2, y_predicao2)\n",
    "adjusted_r_squared2 = 1 - (1 - r_sq2) * (n - 1) / (n - k - 2)  # Ajuste do R^2 para o novo número de variáveis\n",
    "\n",
    "# Exibindo os resultados do novo modelo\n",
    "print(f\"MAE após remoção: {mae2}\")\n",
    "print(f\"RMSE após remoção: {rmse2}\")\n",
    "print(f\"R^2 após remoção: {r_sq2}\")\n",
    "print(f\"R^2 ajustado após remoção: {adjusted_r_squared2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando se trata de modelos de regressão, é fácil ficar preso na complexidade das métricas e das variáveis. Mas, a verdade é que, ao tentar ajustar todos os fatores ao mesmo tempo, o progresso pode ser mínimo. Isso acontece porque o nosso objetivo aqui é otimizar um modelo simples e eficiente, não um que envolva o máximo de variáveis. Assim como no desenvolvimento pessoal, onde tentar crescer em todas as áreas ao mesmo tempo leva à estagnação, no ajuste de um modelo, menos pode ser mais.\n",
    "\n",
    "Ao remover uma variável com baixo impacto, o processo se torna mais leve, os resultados ficam mais claros, e o modelo flui com menos ruído."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
